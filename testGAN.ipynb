{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import mxnet as mx\n",
    "from mxnet import gluon\n",
    "from mxnet import ndarray as nd\n",
    "from mxnet.gluon import nn, utils\n",
    "from mxnet import autograd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import tee\n",
    "def pairwise(iterable):\n",
    "    \"s -> (s0,s1), (s1,s2), (s2, s3), ...\"\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "n_mixture = 8\n",
    "std = 0.025\n",
    "radius = 1.0\n",
    "latent_z_size =100\n",
    "epochs = 2500\n",
    "\n",
    "use_gpu = False\n",
    "ctx = mx.gpu() if use_gpu else mx.cpu()\n",
    "\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "\n",
    "unroll_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-0.00257355 -0.99835177]]\n",
      "\n",
      " [[-0.69356907  0.70192398]]\n",
      "\n",
      " [[ 0.71567027 -0.71396434]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 0.69421498  0.71563563]]\n",
      "\n",
      " [[-0.72877979  0.71346519]]\n",
      "\n",
      " [[ 0.69216986  0.74330703]]]\n"
     ]
    }
   ],
   "source": [
    "thetas = np.linspace(0, 2 * np.pi - 2 * np.pi / n_mixture, n_mixture)\n",
    "centers = []\n",
    "for i in range(0, len(thetas)):\n",
    "    centers.append([radius * np.sin(thetas[i]), radius * np.cos(thetas[i])])\n",
    "samples = []\n",
    "for c in centers:\n",
    "    samples.extend(np.random.normal(loc=c, scale=std, size=[8192, 2]).tolist())\n",
    "#for s in range(len(samples)):\n",
    "#    samples[s] = tf.convert_to_tensor(samples[s])\n",
    "for z in range(len(samples)):\n",
    "    samples[z] = [samples[z]]\n",
    "\n",
    "#test output shape    \n",
    "#o = np.array(samples)\n",
    "#print(o.shape)\n",
    "    \n",
    "random.shuffle(samples)\n",
    "samples = np.asarray(samples)\n",
    "print(samples)\n",
    "#print(samples.T[0:3])\n",
    "train_data = mx.io.NDArrayIter(data = samples, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65536\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc2789aef28>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(samples))\n",
    "print(len(samples[0]))\n",
    "print(len(samples[0][0]))\n",
    "\n",
    "x= samples.T[0][0]\n",
    "y = samples.T[1][0]\n",
    "plt.scatter(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = nn.Sequential()\n",
    "with netG.name_scope():\n",
    "    \n",
    "    #Convolutional\n",
    "    #initially 128 x 100 x 2\n",
    "#     netG.add(nn.Conv1DTranspose(50, 4, in_channels = 100, padding = 2, strides =2))\n",
    "#     netG.add(nn.BatchNorm())\n",
    "#     netG.add(nn.Activation('relu'))\n",
    "#     # should now be 128 x 50 x 2\n",
    "#     netG.add(nn.Conv1DTranspose(25, 4, in_channels = 50, padding = 2, strides =2))\n",
    "#     netG.add(nn.BatchNorm())\n",
    "#     netG.add(nn.Activation('relu'))\n",
    "#     # should still be 128 x 25 x 2\n",
    "#     netG.add(nn.Conv1DTranspose(5, 4, in_channels = 25, padding = 2, strides =2))\n",
    "#     netG.add(nn.BatchNorm())\n",
    "#     netG.add(nn.Activation('relu'))\n",
    "#     #should still be 128 x 5 x 2\n",
    "#     netG.add(nn.Conv1DTranspose(2, 4,  in_channels = 5, padding = 2, strides =2))\n",
    "#     netG.add(nn.BatchNorm())\n",
    "#     netG.add(nn.Activation('relu'))\n",
    "#     #should still be 128 x 2 x 2\n",
    "#     netG.add(nn.Conv1DTranspose(1, 4,  in_channels = 2, padding = 2, strides =2))\n",
    "#     netG.add(nn.LeakyReLU(0.2))\n",
    "#     #should still be 128 x 1 x 2\n",
    "    \n",
    "    \n",
    "    #Dense\n",
    "    #initially 128 x 100 x 2\n",
    "    netG.add(nn.Dense(1280))\n",
    "    netG.add(nn.Dense(640))\n",
    "    netG.add(nn.Dense(320))\n",
    "    netG.add(nn.Dense(2))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD = nn.Sequential()\n",
    "with netD.name_scope():\n",
    "    \n",
    "    #Convolutional\n",
    "    #input is 256 x 1 x 2\n",
    "#     netD.add(nn.Conv1D(channels = 1, kernel_size = 5, padding = 2, in_channels = 1))\n",
    "#     netD.add(nn.LeakyReLU(0.2))\n",
    "#     # should still be 256 x 1 x 2\n",
    "#     netD.add(nn.Conv1D(channels = 1, kernel_size = 5, padding = 2, in_channels = 1))\n",
    "#     netD.add(nn.BatchNorm())\n",
    "#     netD.add(nn.LeakyReLU(0.2))\n",
    "#     # should still be 256 x 1 x 2\n",
    "#     netD.add(nn.Conv1D(channels = 1, kernel_size = 5, padding = 2, in_channels = 1))\n",
    "#     netD.add(nn.BatchNorm())\n",
    "#     netD.add(nn.LeakyReLU(0.2))\n",
    "#     # should still be 256 x 1 x 2\n",
    "#     netD.add(nn.Conv1D(channels = 1, kernel_size = 5, padding = 2, in_channels = 1))\n",
    "#     netD.add(nn.BatchNorm())\n",
    "#     netD.add(nn.LeakyReLU(0.2))\n",
    "#     # should still be 256 x 1 x 2\n",
    "#     netD.add(nn.Conv1D(channels = 1, kernel_size = 5, strides = 2,padding = 2, in_channels = 1))\n",
    "#     # should still be 256 x 1 x 1\n",
    "\n",
    "\n",
    "    #Dense\n",
    "    netD.add(nn.Dense(200))\n",
    "    netD.add(nn.Dense(400 ,activation='tanh'))\n",
    "    netD.add(nn.Dense(300 ,activation='tanh'))\n",
    "    netD.add(nn.Dense(1))\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gluon.loss.SigmoidBinaryCrossEntropyLoss()\n",
    "\n",
    "netG.initialize(mx.init.Normal(0.02), ctx = ctx)\n",
    "netD.initialize(mx.init.Normal(0.02), ctx = ctx)\n",
    "\n",
    "trainerG = gluon.Trainer(netG.collect_params(), 'adam', {'learning_rate': lr, 'beta1':beta1})\n",
    "trainerD = gluon.Trainer(netD.collect_params(), 'adam', {'learning_rate': lr, 'beta1':beta1})\n",
    "unrolledtrainerD = gluon.Trainer(netD.collect_params(), 'adam', {'learning_rate': lr, 'beta1':beta1})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import logging\n",
    "\n",
    "real_label = nd.ones((batch_size * 2,), ctx = ctx)\n",
    "fake_label = nd.zeros((batch_size * 2,), ctx = ctx)\n",
    "\n",
    "def facc(label, pred):\n",
    "    pred = pred.ravel()\n",
    "    label = label.ravel()\n",
    "    return ((pred>0.5) == label).mean()\n",
    "metric = mx.metric.CustomMetric(facc)\n",
    "\n",
    "\n",
    "stamp =  datetime.now().strftime('%Y_%m_%d-%H_%M')\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "\n",
    "#set up Discriminator first\n",
    "\n",
    "# for i in range(250):\n",
    "#     tic = time.time()\n",
    "#     btic = time.time()\n",
    "#     train_data.reset()\n",
    "#     iter = 0\n",
    "#     #print(\"RUNNING\")\n",
    "#     for batch1firstFake , batch2 in pairwise(train_data):\n",
    "#         ############################\n",
    "#         # (1) Update D network: maximizemr jones ukulele log(D(x)) + log(1 - D(G(z)))\n",
    "#         ###########################\n",
    "\n",
    "#         data = (mx.ndarray.concat(batch1.data[0], batch2.data[0], dim = 0)).as_in_context(ctx)\n",
    "        \n",
    "#         #print(\"THIS IS A CHECK\")\n",
    "#         #print(data)\n",
    "#         #print(len(data))\n",
    "#         #print(len(data[0]))\n",
    "#         #print(len(data[0][0]))\n",
    "#         #print(len(batch1.data[0]))\n",
    "#         #print(len(batch1.data[0][0]))\n",
    "#         #print(len(batch1.data[0][0][0]))\n",
    "#         #print(len(batch2.data[0]))\n",
    "#         #print(len(batch2.data[0][0]))\n",
    "#         #print(len(batch2.data[0][0][0]))\n",
    "#         #print(data)\n",
    "        \n",
    "        \n",
    "#         latent_z1 = mx.nd.random_normal(0, 1, shape=(batch_size, latent_z_size, 2), ctx=ctx)\n",
    "#         latent_z2 = mx.nd.random_normal(0, 1, shape=(batch_size, latent_z_size, 2), ctx=ctx)\n",
    "\n",
    "#         with autograd.record():\n",
    "#             # train with real image\n",
    "#             output = netD(data).reshape((-1, 1))\n",
    "#             errD_real = loss(output, real_label)\n",
    "#             #print(\"This is the guess for real\")\n",
    "#             #print(output)\n",
    "#             metric.update([real_label,], [output,])\n",
    "\n",
    "#             # train with fake image\n",
    "#             firstFake = netG(latent_z1)\n",
    "#             secondFake = netG(latent_z2)\n",
    "            \n",
    "#             #only add if using dense\n",
    "#             firstFake = firstFake.reshape((128, 1, 2))\n",
    "#             secondFake = secondFake.reshape((128, 1, 2))\n",
    "            \n",
    "#             fake = mx.ndarray.concat(firstFake, secondFake, dim = 0)\n",
    "#             #print(\"TESTING\")\n",
    "#             #print(len(fake))\n",
    "#             output = netD(fake.detach()).reshape((-1, 1))\n",
    "#             errD_fake = loss(output, fake_label)\n",
    "#             errD = errD_real + errD_fake\n",
    "#             errD.backward()\n",
    "#             metric.update([fake_label,], [output,])\n",
    "\n",
    "#         trainerD.step(batch.data[0].shape[0])\n",
    "#     name, acc = metric.get()\n",
    "#     metric.reset()\n",
    "    \n",
    "# print(\"Done setting up Discriminator\")\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_data.reset()\n",
    "    tic = time.time()\n",
    "    btic = time.time()\n",
    "    iter = 0\n",
    "    #print(\"RUNNING\")\n",
    "    for batch1, batch2 in pairwise(train_data):\n",
    "        ############################\n",
    "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "        ###########################\n",
    "\n",
    "        data = (mx.ndarray.concat(batch1.data[0], batch2.data[0], dim = 0)).as_in_context(ctx)\n",
    "        \n",
    "        #print(\"THIS IS A CHECK\")\n",
    "        #print(data)\n",
    "        #print(len(data))\n",
    "        #print(len(data[0]))\n",
    "        #print(len(data[0][0]))\n",
    "        #print(len(batch1.data[0]))\n",
    "        #print(len(batch1.data[0][0]))\n",
    "        #print(len(batch1.data[0][0][0]))\n",
    "        #print(len(batch2.data[0]))\n",
    "        #print(len(batch2.data[0][0]))\n",
    "        #print(len(batch2.data[0][0][0]))\n",
    "        #print(data)\n",
    "        \n",
    "        \n",
    "        latent_z1 = mx.nd.random_normal(0, 1, shape=(batch_size, latent_z_size, 2), ctx=ctx)\n",
    "        latent_z2 = mx.nd.random_normal(0, 1, shape=(batch_size, latent_z_size, 2), ctx=ctx)\n",
    "\n",
    "        with autograd.record():\n",
    "            # train with real image\n",
    "            #print(\"Real Data\")\n",
    "            #print(data)\n",
    "            output = netD(data).reshape((-1, 1))\n",
    "            #print(\"Output of Discriminator\")\n",
    "            #print(output)\n",
    "            errD_real = loss(output, real_label)\n",
    "            #print(\"This is the guess for real\")\n",
    "            #print(output)\n",
    "            metric.update([real_label,], [output,])\n",
    "\n",
    "            # train with fake image\n",
    "            firstFake = netG(latent_z1)\n",
    "            secondFake = netG(latent_z2)\n",
    "            #print(\"testing 1\")\n",
    "            #print(firstFake)\n",
    "            \n",
    "            #only add if using dense\n",
    "            #firstFake = firstFake.reshape((128, 1, 2))\n",
    "            #secondFake = secondFake.reshape((128, 1, 2))  \n",
    "            #print(\"testing 2\")\n",
    "            #print(firstFake)\n",
    "            \n",
    "\n",
    "            fake = mx.ndarray.concat(firstFake, secondFake, dim = 0)\n",
    "            #print(\"TESTING\")\n",
    "            #print(len(fake))\n",
    "            output = netD(fake.detach()).reshape((-1, 1))\n",
    "            errD_fake = loss(output, fake_label)\n",
    "            errD = errD_real + errD_fake\n",
    "            errD.backward()\n",
    "            metric.update([fake_label,], [output,])\n",
    "\n",
    "        trainerD.step(batch.data[0].shape[0])\n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network: maximize log(D(G(z)))\n",
    "        ###########################\n",
    "        with autograd.record():\n",
    "            fake1 = netG(latent_z1)\n",
    "            fake2 = netG(latent_z2)\n",
    "            #print(fake1)\n",
    "            #rint(fake1.T)\n",
    "            #print(fake1.T[0])\n",
    "           # print(fake1.T[0][1])\n",
    "            \n",
    "            \n",
    "            #only add if using dense\n",
    "            #fake1 = fake1.reshape((128, 1, 2))\n",
    "            #fake2 = fake2.reshape((128, 1, 2))\n",
    "            \n",
    "            output = netD(mx.ndarray.concat(fake1, fake2, dim = 0)).reshape((-1, 1))\n",
    "            errG = loss(output, real_label)\n",
    "            errG.backward()\n",
    "\n",
    "        trainerG.step((batch1.data[0] +batch2.data[0]).shape[0])\n",
    "\n",
    "        # Print log infomation every ten batches\n",
    "        if iter % 10 == 0:\n",
    "            name, acc = metric.get()\n",
    "            #logging.firstFake info('speed: {} samples/s'.format(batch_size / (time.time() - btic)))\n",
    "            #logging.info('discriminator loss = %f, generator loss = %f, binary training acc = %f at iter %d epoch %d'\n",
    "            #         %(nd.mean(errD).asscalar(),\n",
    "            #           nd.mean(errG).asscalar(), acc, iter, epoch))\n",
    "        iter = iter + 1\n",
    "        btic = time.time()\n",
    "\n",
    "    name, acc = metric.get()\n",
    "    metric.reset()\n",
    "    #logging.info('\\nbinary training acc at epoch %d: %s=%f' % (epoch, name, acc))\n",
    "    #logging.info('time: %f' % (time.time() - tic))\n",
    "\n",
    "    #Visualize one generated image for each epoch\n",
    "    fake_img = fake1[0]\n",
    "    #print(fake1)\n",
    "    #print(len(fake))\n",
    "    #print(len(fake[0]))\n",
    "    #print(len(fake[0][0]))\n",
    "    #print(fake)\n",
    "    \n",
    "    \n",
    "    #test small print\n",
    "    #print(\"epoch %d\" % (epoch))\n",
    "    #print(\"X: %s   Y: %s  \" % (fake_img[0][0],fake_img[0][1]))\n",
    "    #x= fake.T[0][0].asnumpy().tolist()\n",
    "    #y = fake.T[1][0].asnumpy().tolist()\n",
    "    #print(\"Plot\")\n",
    "    #plt.scatter(x,y)\n",
    "    #plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #real print\n",
    "    if(epoch%250 == 0):\n",
    "        logging.info('\\nbinary training acc at epoch %d: %s=%f' % (epoch, name, acc))\n",
    "        logging.info('time: %f' % (time.time() - tic))\n",
    "        logging.info('time: %f' % (time.time() - tic))\n",
    "        print(\"epoch %d\" % (epoch))\n",
    "        \n",
    "        #For convolution?\n",
    "        #print(\"X: %s   Y: %s  \" % (fake_img[0][0],fake_img[0][1]))\n",
    "        #x= fake1.T[0][0].asnumpy().tolist()\n",
    "        #y = fake1.T[1][0].asnumpy().tolist()\n",
    "        \n",
    "        x = fake1.T[0].asnumpy().tolist()\n",
    "        y = fake1.T[1].asnumpy().tolist()\n",
    "        print(\"X: \")\n",
    "        print(fake1.T[0][0])\n",
    "        print(\"Y: \")\n",
    "        print(fake1.T[0][1])\n",
    "\n",
    "        print(\"Plot\")\n",
    "        plt.scatter(x,y)\n",
    "        plt.show()\n",
    "    \n",
    "    # visualize(fake_img)\n",
    "    # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
